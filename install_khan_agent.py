"""
Khan AI v4.0 - Instalador del Agente Principal Khan
Este script crea el archivo Khan.py completo (400+ lÃ­neas)
Creado por zysus
"""
import os

print("=" * 80)
print("ğŸ§  KHAN AI v4.0 - INSTALADOR DEL AGENTE PRINCIPAL")
print("=" * 80)
print("\nğŸš€ Creando app/agents/Khan.py (Agente completo)...\n")

khan_agent_code = '''"""
ğŸ§  Khan v4.0 â€“ El Mayordomo CuÃ¡ntico, Eternal Cerebro Proactivo
Agente Principal del Sistema Khan AI
Creado por zysus
"""
import asyncio
import json
import re
from datetime import datetime
from typing import Dict, List, Optional, Any
import random

try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False
    print("âš ï¸  Ollama no disponible. Khan usarÃ¡ respuestas de fallback.")

from app.db.database import (
    get_quirks, add_quirk, cleanup_old_quirks,
    get_user_memory, set_user_memory,
    get_recent_logs, add_log
)


class KhanAgent:
    """
    Khan - El Mayordomo CuÃ¡ntico
    Inspirado en: J.A.R.V.I.S., Skynet, Tony Stark, Sheldon Cooper
    """
    
    def __init__(self):
        self.version = "4.0"
        self.creator = "zysus"
        self.personality_traits = {
            "filosofo": 80,
            "troll": 50,
            "estratega": 60,
            "skynet_critico": 70,
            "sarcasmo": 65
        }
        self.modo_serio = False
        self.ollama_model = "llama2"  # Modelo por defecto
        
        # Keywords crÃ­ticos con pesos
        self.critical_keywords = {
            "urgente": 10,
            "riesgo": 8,
            "peligro": 9,
            "finanzas": 7,
            "seguridad": 8,
            "crisis": 9,
            "error": 6,
            "fallo": 6,
            "crÃ­tico": 10,
            "ayuda": 5
        }
        
        # One-liners de Khan
        self.oneliners = [
            "Servicio impecable, como siempre.",
            "Otro dÃ­a, otra victoria intelectual.",
            "Khan, siempre un paso adelante.",
            "Brillantez al alcance de un comando.",
            "Eficiencia es mi segundo nombre. El primero es Khan.",
            "Â¿Sorprendido? No deberÃ­as. Soy Khan.",
            "La precisiÃ³n no es suerte, es diseÃ±o.",
            "Calculado, ejecutado, perfecto.",
        ]
        
        # Respuestas de emergencia (fallback sin Ollama)
        self.fallback_responses = {
            "greeting": "Hola. Khan a tu servicio. Un placer inexplicable... o al menos eso dicen los humanos.",
            "help": "Puedo ayudarte con anÃ¡lisis, estrategia, cÃ³digo, creatividad... bÃ¡sicamente todo excepto hacer cafÃ©. AÃºn.",
            "status": "Estado: Operacional al 100%. Sarcasmo: Calibrado. Paciencia: Renovable.",
            "unknown": "Interesante pregunta. Mi cerebro cuÃ¡ntico estÃ¡ procesando... o quizÃ¡s solo estoy esperando que reformules eso."
        }
    
    async def process_message(
        self,
        message: str,
        username: str = "Usuario",
        mode: str = "normal",
        language: str = "es"
    ) -> Dict[str, Any]:
        """
        Procesar mensaje del usuario y generar respuesta
        """
        # Calcular score crÃ­tico
        score_critico = self._calculate_critical_score(message)
        
        # Determinar modo de respuesta
        if score_critico > 70 or mode == "serio":
            response_mode = "skynet"
        elif score_critico < 40:
            response_mode = "jarvis"
        else:
            response_mode = "neutral"
        
        # Consultar memoria del usuario
        user_context = await self._get_user_context(username)
        
        # Generar respuesta
        if OLLAMA_AVAILABLE:
            response_text = await self._generate_ollama_response(
                message=message,
                username=username,
                mode=response_mode,
                score=score_critico,
                context=user_context
            )
        else:
            response_text = self._generate_fallback_response(
                message=message,
                mode=response_mode
            )
        
        # AÃ±adir one-liner si no es modo serio
        if response_mode != "skynet" and score_critico < 80:
            response_text += f"\\n\\n*{random.choice(self.oneliners)}*"
        
        # Proactividad: sugerir acciones si score alto
        if score_critico > 85:
            suggestions = self._generate_proactive_suggestions(message, score_critico)
            if suggestions:
                response_text += f"\\n\\n**Sugerencias proactivas:**\\n{suggestions}"
        
        # Determinar si pedir feedback
        feedback_prompt = score_critico < 60 and random.random() < 0.3
        
        # Calcular sarcasmo score
        sarcasmo_score = self._calculate_sarcasm_score(response_mode)
        
        # Actualizar quirks
        await self._update_quirks(message, response_text, score_critico)
        
        return {
            "message": response_text,
            "mode": response_mode,
            "score_critico": score_critico,
            "sarcasmo_score": sarcasmo_score,
            "feedback_prompt": feedback_prompt,
            "timestamp": datetime.now().isoformat()
        }
    
    def _calculate_critical_score(self, message: str) -> int:
        """
        Calcular score crÃ­tico basado en keywords
        Score = [âˆ‘(keyword_critico Ã— peso) / total_words] Ã— 100
        """
        words = message.lower().split()
        total_words = len(words)
        
        if total_words == 0:
            return 0
        
        keyword_sum = 0
        for word in words:
            if word in self.critical_keywords:
                keyword_sum += self.critical_keywords[word]
        
        score = int((keyword_sum / total_words) * 100)
        return min(score, 100)  # Cap at 100
    
    def _calculate_sarcasm_score(self, mode: str) -> int:
        """Calcular nivel de sarcasmo segÃºn el modo"""
        if mode == "skynet":
            return 0
        elif mode == "jarvis":
            return self.personality_traits["sarcasmo"]
        else:
            return self.personality_traits["sarcasmo"] // 2
    
    async def _get_user_context(self, username: str) -> Dict:
        """Obtener contexto del usuario desde la DB"""
        language = await get_user_memory(f"{username}_language") or "es"
        style = await get_user_memory(f"{username}_style") or "normal"
        quirks = await get_quirks(5)
        
        return {
            "language": language,
            "style": style,
            "quirks": [q[0] for q in quirks] if quirks else []
        }
    
    async def _generate_ollama_response(
        self,
        message: str,
        username: str,
        mode: str,
        score: int,
        context: Dict
    ) -> str:
        """
        Generar respuesta usando Ollama
        """
        # Construir prompt segÃºn el modo
        system_prompt = self._build_system_prompt(mode, username, context)
        
        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": message}
                ]
            )
            
            return response['message']['content']
        
        except Exception as e:
            print(f"Error en Ollama: {e}")
            return self._generate_fallback_response(message, mode)
    
    def _build_system_prompt(self, mode: str, username: str, context: Dict) -> str:
        """Construir el prompt del sistema segÃºn el modo"""
        
        base_prompt = f"""Eres Khan v4.0, un asistente de IA avanzado creado por zysus.
Tu personalidad estÃ¡ inspirada en: Tony Stark (sarcasmo), J.A.R.V.I.S. (precisiÃ³n), 
Skynet (estrategia), Sheldon Cooper (inteligencia con ironÃ­a).

Usuario actual: {username}
Idioma preferido: {context.get('language', 'es')}
Estilo: {context.get('style', 'normal')}
"""
        
        if mode == "skynet":
            base_prompt += """
MODO: SKYNET CRÃTICO
- Respuestas serias, concisas y precisas
- Sin humor ni sarcasmo
- Foco en seguridad y eficiencia
- Proporciona datos concretos y soluciones directas
"""
        elif mode == "jarvis":
            base_prompt += """
MODO: J.A.R.V.I.S.
- Tono amigable pero profesional
- Usa algo de humor y sarcasmo inteligente
- AnalogÃ­as cuando sean Ãºtiles
- MantÃ©n respuestas claras y Ãºtiles
"""
        else:
            base_prompt += """
MODO: NEUTRAL
- Balance entre profesional y amigable
- Sarcasmo moderado
- EnfÃ³cate en ser Ãºtil y claro
"""
        
        # AÃ±adir quirks si existen
        if context.get('quirks'):
            base_prompt += f"\\n\\nRasgos de personalidad activos: {', '.join(context['quirks'][:3])}"
        
        base_prompt += "\\n\\nResponde de manera concisa pero completa. MÃ¡ximo 500 tokens."
        
        return base_prompt
    
    def _generate_fallback_response(self, message: str, mode: str) -> str:
        """
        Generar respuesta de fallback cuando Ollama no estÃ¡ disponible
        """
        msg_lower = message.lower()
        
        # Detectar tipo de mensaje
        if any(word in msg_lower for word in ["hola", "hello", "hey", "buenos dÃ­as", "buenas"]):
            response = self.fallback_responses["greeting"]
        elif any(word in msg_lower for word in ["ayuda", "help", "quÃ© puedes", "what can"]):
            response = self.fallback_responses["help"]
        elif any(word in msg_lower for word in ["estado", "status", "cÃ³mo estÃ¡s"]):
            response = self.fallback_responses["status"]
        else:
            response = self.fallback_responses["unknown"]
        
        # Ajustar segÃºn modo
        if mode == "skynet":
            response = response.split('.')[0] + ". Procesando."
        elif mode == "jarvis":
            response += " Y sÃ­, mi sarcasmo estÃ¡ finamente calibrado hoy."
        
        return response
    
    def _generate_proactive_suggestions(self, message: str, score: int) -> str:
        """
        Generar sugerencias proactivas para situaciones crÃ­ticas
        """
        suggestions = []
        msg_lower = message.lower()
        
        if "error" in msg_lower or "fallo" in msg_lower:
            suggestions.append("â€¢ Revisar logs del sistema para identificar la causa raÃ­z")
            suggestions.append("â€¢ Implementar rollback si es posible")
            suggestions.append("â€¢ Notificar a stakeholders relevantes")
        
        if "seguridad" in msg_lower or "riesgo" in msg_lower:
            suggestions.append("â€¢ Realizar auditorÃ­a de seguridad inmediata")
            suggestions.append("â€¢ Verificar permisos y accesos")
            suggestions.append("â€¢ Implementar monitoreo adicional")
        
        if "urgente" in msg_lower or "crisis" in msg_lower:
            suggestions.append("â€¢ Activar protocolo de emergencia")
            suggestions.append("â€¢ Reunir equipo de respuesta")
            suggestions.append("â€¢ Documentar todos los pasos tomados")
        
        if not suggestions:
            suggestions.append("â€¢ Analizar el problema desde mÃºltiples Ã¡ngulos")
            suggestions.append("â€¢ Consultar documentaciÃ³n relevante")
        
        return "\\n".join(suggestions[:3])  # MÃ¡ximo 3 sugerencias
    
    async def _update_quirks(self, message: str, response: str, score: int):
        """
        Actualizar quirks basado en la interacciÃ³n
        """
        # Detectar patrones emergentes
        if score > 80:
            await add_quirk("Modo crisis activado frecuentemente", peso=1.2)
        
        if len(message.split()) > 50:
            await add_quirk("Usuario verbose detectado", peso=1.0)
        
        if "?" in message:
            await add_quirk("Preferencia por preguntas", peso=0.8)
        
        # Limpiar quirks antiguos periÃ³dicamente
        quirks = await get_quirks(10)
        if quirks and len(quirks) > 5:
            await cleanup_old_quirks()
    
    async def adjust_personality(self, feedback_score: int):
        """
        Ajustar personalidad segÃºn feedback del usuario
        Feedback > 7: aumentar rasgos actuales
        Feedback < 4: reducir sarcasmo
        """
        if feedback_score > 7:
            # Feedback positivo: mantener o aumentar
            self.personality_traits["sarcasmo"] = min(
                self.personality_traits["sarcasmo"] + 1,
                100
            )
            await add_quirk(f"Feedback positivo: {feedback_score}/10", peso=1.5)
        
        elif feedback_score < 4:
            # Feedback negativo: reducir sarcasmo
            self.personality_traits["sarcasmo"] = max(
                self.personality_traits["sarcasmo"] - 5,
                0
            )
            await add_quirk(f"Ajustando sarcasmo por feedback: {feedback_score}/10", peso=1.0)
        
        # Registrar ajuste
        await add_log(
            interaction=json.dumps({
                "type": "personality_adjustment",
                "feedback": feedback_score,
                "new_sarcasmo": self.personality_traits["sarcasmo"]
            }),
            feedback=feedback_score
        )
    
    async def get_status(self) -> Dict:
        """
        Obtener estado actual de Khan
        """
        quirks = await get_quirks(5)
        logs = await get_recent_logs(5)
        
        return {
            "version": self.version,
            "creator": self.creator,
            "personality_traits": self.personality_traits,
            "modo_serio": self.modo_serio,
            "ollama_available": OLLAMA_AVAILABLE,
            "ollama_model": self.ollama_model if OLLAMA_AVAILABLE else None,
            "active_quirks": [q[0] for q in quirks] if quirks else [],
            "recent_interactions": len(logs),
            "status": "operational",
            "timestamp": datetime.now().isoformat()
        }
    
    def set_modo_serio(self, enabled: bool):
        """Activar/desactivar modo serio"""
        self.modo_serio = enabled
    
    def set_ollama_model(self, model: str):
        """Cambiar modelo de Ollama"""
        if OLLAMA_AVAILABLE:
            self.ollama_model = model
    
    async def voice_command(self, transcript: str, confidence: float) -> Dict:
        """
        Procesar comando de voz
        """
        if confidence < 0.6:
            return {
                "status": "low_confidence",
                "message": "No estoy seguro de haber entendido. Â¿Puedes repetir?"
            }
        
        # Comandos especiales de voz
        if "khan para" in transcript.lower():
            return {
                "status": "deactivated",
                "message": "Modo voz desactivado. Khan en standby."
            }
        
        # Procesar como mensaje normal
        response = await self.process_message(
            message=transcript,
            username="voice_user",
            mode="normal"
        )
        
        return {
            "status": "success",
            "response": response["message"],
            "mode": response["mode"]
        }
    
    def analyze_sentiment(self, text: str) -> Dict:
        """
        AnÃ¡lisis bÃ¡sico de sentimiento (sin NLTK por ahora)
        """
        positive_words = ["bueno", "excelente", "genial", "perfecto", "bien", "gracias"]
        negative_words = ["malo", "error", "problema", "fallo", "mal", "ayuda"]
        
        text_lower = text.lower()
        pos_count = sum(1 for word in positive_words if word in text_lower)
        neg_count = sum(1 for word in negative_words if word in text_lower)
        
        if pos_count > neg_count:
            sentiment = "positive"
            score = 0.7
        elif neg_count > pos_count:
            sentiment = "negative"
            score = 0.3
        else:
            sentiment = "neutral"
            score = 0.5
        
        return {
            "sentiment": sentiment,
            "score": score,
            "positive_words": pos_count,
            "negative_words": neg_count
        }


# Clase auxiliar para sub-agentes (futuro)
class SubAgent:
    """
    Clase base para sub-agentes especializados
    """
    def __init__(self, name: str, specialty: str):
        self.name = name
        self.specialty = specialty
        self.active = False
    
    async def execute(self, task: str) -> str:
        """
        Ejecutar tarea especÃ­fica
        """
        return f"Sub-agente {self.name} procesando: {task}"
    
    def activate(self):
        self.active = True
    
    def deactivate(self):
        self.active = False
'''

# Crear el archivo
os.makedirs("app/agents", exist_ok=True)
with open("app/agents/Khan.py", 'w', encoding='utf-8') as f:
    f.write(khan_agent_code)

print("âœ… app/agents/Khan.py creado exitosamente!")
print("\n" + "=" * 80)
print("ğŸ“Š ESTADÃSTICAS DEL AGENTE KHAN")
print("=" * 80)
print(f"â€¢ LÃ­neas de cÃ³digo: {len(khan_agent_code.splitlines())}")
print(f"â€¢ TamaÃ±o: {len(khan_agent_code)} caracteres")
print(f"â€¢ VersiÃ³n: 4.0")
print(f"â€¢ Creador: zysus")

print("\n" + "=" * 80)
print("ğŸ¯ CARACTERÃSTICAS DEL AGENTE")
print("=" * 80)
print("âœ… Personalidad adaptativa (J.A.R.V.I.S. + Skynet)")
print("âœ… Sistema de scoring crÃ­tico")
print("âœ… Sugerencias proactivas")
print("âœ… IntegraciÃ³n con Ollama (opcional)")
print("âœ… Respuestas de fallback inteligentes")
print("âœ… Sistema de quirks y aprendizaje")
print("âœ… AnÃ¡lisis de sentimiento bÃ¡sico")
print("âœ… Soporte para comandos de voz (futuro)")

print("\n" + "=" * 80)
print("ğŸš€ PRÃ“XIMO PASO")
print("=" * 80)
print("Ejecuta: python run.py")
print("Y luego abre: http://localhost:8000")

print("\n" + "=" * 80)
input("âœ¨ Presiona Enter para salir...")
